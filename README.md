# TRC AI Front End

This project provides an interface for the Reward Collection tools. Files for the Knowledge Base are stored in Supabase Storage and used to enrich GPT replies on the home page.

## Supabase Setup

1. [Create a Supabase project](https://supabase.com/).
2. In your project, create a bucket named `knowledge_base` and make it
   **public**. Upload your documents directly into this bucket using the
   Supabase dashboard or API. Files are used to enrich GPT replies.
3. Copy your project URL and anon key from the Supabase dashboard.
4. Create a `.env.local` file in this repo and set:
   ```
   NEXT_PUBLIC_SUPABASE_URL=your-project-url
   NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
   OPENAI_API_KEY=your-openai-key
   SUPABASE_URL=your-project-url
   SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
   ```
5. Create the table used to store extracted text:
   ```sql
   create table public.knowledge_base_entries (
     id bigint generated by default as identity primary key,
     uploaded_at timestamp with time zone not null default now(),
     file_name text,
     file_url text,
     file_type text,
     extracted_text text
   );
   ```
6. Enable Row Level Security and add policies allowing inserts/selects for anonymous users on `knowledge_base` and `knowledge_base_entries`.

7. Create an Edge Function `extract-text-from-upload` that listens for `storage.object.created` events on the `knowledge_base` bucket. The function downloads the new file, extracts text, and inserts a row into `knowledge_base_entries`. Deploy it with:
   ```bash
   supabase functions deploy extract-text-from-upload --no-verify-jwt
   supabase functions invoke extract-text-from-upload
   ```
   Ensure the following environment variables are provided when deploying:
   `PROJECT_URL` and `SERVICE_ROLE_KEY`.

8. Install dependencies and run the development server:
   ```
   npm install
   npm run dev
   ```

Uploaded files in the `knowledge_base` bucket are parsed automatically and saved
to the `knowledge_base_entries` table. The home page GPT tools pull context from
this table and from the `Merchants` and `Publishers` tables. Because GPT can
only process a limited amount of text, the API summarises these tables before
sending them to OpenAI. When questions ask for live counts or lists, the API
queries Supabase in real time to return accurate numbers. For contractual or
policy questions it searches the `knowledge_base_entries.extracted_text` column
and includes the most relevant passages.

The home page includes a Draft Reply tool that can generate email responses. Use
the **Tone Enhancer** dropdown to tailor the reply for roles such as Sales,
Account Manager or Legal.

## Testing Page

Visit `/testing` to see the exact data loaded from Supabase and passed to GPT.
The page lists **all** Merchants, **all** Publishers and every knowledge base
entry in your project. Use this page to verify that GPT has access to the full
dataset. If you have thousands of rows consider adding pagination or filtering
when browsing this page.
